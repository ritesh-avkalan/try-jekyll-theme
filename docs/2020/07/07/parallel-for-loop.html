<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name = "keywords" content = "fenics, topology optimization, isogeomtric analysis, hpc, phd blog, paraview, latex, computational mechanics, phd tools, parallel computation, python, phase field fracture, phase field topology optimization" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Parallelizing for loop in python with MPI." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Solving real world applications demands parallel computation." />
<meta property="og:description" content="Solving real world applications demands parallel computation." />
<link rel="canonical" href="https://ritesh-avkalan.github.io//try-jekyll-theme/2020/07/07/parallel-for-loop.html" />
<meta property="og:url" content="https://ritesh-avkalan.github.io//try-jekyll-theme/2020/07/07/parallel-for-loop.html" />
<meta property="og:site_name" content="Abhinav Gupta" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-07T00:00:00+05:30" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Parallelizing for loop in python with MPI." />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-07-07T00:00:00+05:30","datePublished":"2020-07-07T00:00:00+05:30","description":"Solving real world applications demands parallel computation.","headline":"Parallelizing for loop in python with MPI.","mainEntityOfPage":{"@type":"WebPage","@id":"https://ritesh-avkalan.github.io//try-jekyll-theme/2020/07/07/parallel-for-loop.html"},"url":"https://ritesh-avkalan.github.io//try-jekyll-theme/2020/07/07/parallel-for-loop.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/try-jekyll-theme/assets/css/main.css" type="text/css" media="all" />




  <link rel="shortcut icon" type="image/x-icon" href="/?" />
    <title> 
     
      Parallelizing for loop in python with MPI. | 
    
    Abhinav Gupta
  </title>


  <!-- MailerLite Universal -->
  <script>
      (function(w,d,e,u,f,l,n){w[f]=w[f]||function(){(w[f].q=w[f].q||[])
      .push(arguments);},l=d.createElement(e),l.async=1,l.src=u,
      n=d.getElementsByTagName(e)[0],n.parentNode.insertBefore(l,n);})
      (window,document,'script','https://assets.mailerlite.com/js/universal.js','ml');
      ml('account', '325878');
  </script>
  <!-- End MailerLite Universal --><link type="application/atom+xml" rel="alternate" href="https://ritesh-avkalan.github.io//try-jekyll-theme/feed.xml" title="Abhinav Gupta" /></head><body class="full_width_container"><div class="navbar-container">
    <div class="primary_container ">
        <a class="link home-icon" href="https://ritesh-avkalan.github.io/">
                <svg width="76px" height="100%" viewBox="0 0 63 40" >
                    <path d="M29.585,14.07l0.085,1.138l8.46,19.638l0.896,0.906c0.279,0.125 0.564,0.243 0.854,0.355c2.201,0.852 4.618,1.284 7.253,1.284c5.057,0 9.628,-1.101 13.717,-3.286l0.925,-1.544l0,-15.928l-1.75,-1.75l-11.924,0l-1.75,1.75l0,5.016l1.75,1.75l4.63,0c0,0 0,4.518 0,4.518c-0.594,0.254 -1.239,0.453 -1.934,0.6c-1.134,0.24 -2.34,0.358 -3.62,0.358c-1.348,0 -2.57,-0.236 -3.66,-0.726c-1.083,-0.487 -2.014,-1.154 -2.792,-2.005c-0.789,-0.862 -1.394,-1.888 -1.826,-3.07c-0.446,-1.225 -0.664,-2.566 -0.664,-4.021c0,-1.332 0.216,-2.577 0.656,-3.734c0.431,-1.132 1.037,-2.125 1.825,-2.974c0.777,-0.837 1.706,-1.49 2.786,-1.963c1.095,-0.48 2.321,-0.711 3.675,-0.711c1.37,0 2.671,0.226 3.901,0.683c1.182,0.438 2.192,1.054 3.02,1.859l2.463,-0.025l4.092,-4.136l-0.078,-2.536c-1.849,-1.651 -3.946,-2.797 -6.29,-3.44c-2.228,-0.612 -4.611,-0.921 -7.152,-0.921c-2.635,0 -5.052,0.432 -7.253,1.284c-2.243,0.867 -4.172,2.106 -5.792,3.71c-1.617,1.601 -2.887,3.534 -3.802,5.804c-0.275,0.683 -0.509,1.388 -0.701,2.117Z" style="fill-rule:nonzero;"/><path d="M16.141,3.21l-1.604,1.052l-13.552,31.152l1.604,2.448l6.204,0l1.628,-1.107l2.379,-6.021c-0,0 11.141,0 11.141,0c-0,0 2.46,6.038 2.46,6.038l1.62,1.09l6.336,0l1.608,-2.442l-13.42,-31.152l-1.608,-1.058l-4.796,0Zm4.507,19.272l-4.597,0c0,0 2.32,-6.017 2.32,-6.017l2.277,6.017Z" style="fill-rule:nonzero;"/>
                </svg>
        </a>
        <div class="navbar align_menu" style="font-family: Montserrat; font-weight:500">
            <a class="link" href="https://ritesh-avkalan.github.io//pages/blog">Articles</a>
            <a class="link" href="https://ritesh-avkalan.github.io//pages/projects">Projects</a>
            <a class="link nav_desktop" href="https://ritesh-avkalan.github.io//pages/newsletters">Newsletter</a>
            <a class="link" href="https://ritesh-avkalan.github.io//pages/about">About</a>
            <a href="/2020/07/07/parallel-for-loop.html" id="theme-toggle" onclick="modeSwitcher()" style="cursor: pointer;">Dark</a>
        </div>
    </div>
</div><main aria-label="Content">
        <div>
            <div class="post_container">
    <div class="post_item_left" style=" padding-bottom:50px; ">
        <div class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

            <head>
                <title>Parallelizing for loop in python with MPI.</title>
                <script type="text/x-mathjax-config">
                    MathJax.Hub.Config({
                    extensions: ["tex2jax.js"],
                    jax: ["input/TeX", "output/HTML-CSS"],
                    tex2jax: {
                      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                      processEscapes: true
                    },
                    "HTML-CSS": { availableFonts: ["TeX"] }
                  });
                </script>
                <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
            </head>
            <header class="post-header" style="margin-bottom: 60px;">
                <h1 style="font-weight:600; font-size: 46px; margin-top: 120px; " class="post-title p-name" itemprop="name headline">
                    Parallelizing for loop in python with MPI.
                </h1>
                <p class="post-meta" style="font-size: 16px;">
                    <time class="dt-published" datetime="2020-07-07T00:00:00+05:30" itemprop="datePublished">Jul 7, 2020
                    </time><span style="padding-left:10px;padding-right: 10px;">|</span><span class="post-meta"><a style="font-size:14px;color: var(--text-color);" href="https://ritesh-avkalan.github.io//categories/coding">CODING</a></span><!-- --------------------------------------- -->
                </p>
            </header>
            <hr style="/*position: relative; width: 300%;right:calc(200% - 30px);*/ background: var(--color-1);border: none;height: 1px; margin-bottom: 80px; opacity: 1;">
            <div class="post-content e-content enlarged-char" itemprop="articleBody">
                <p>Parallel computing is necessary for venturing into the world of high performance computing. Parallel computing as the name suggests allows us to run a program parallelly. The preferred language of choice in our lab is Python and we can achieve parallel computation in python with the help of ‘mpi4py’ module. This comes with the standard installation of FEniCS, so if you have FEniCS installed on your system then you can directly work with MPI.</p>

<p>This post is based on my very limited understanding of the working of parallel programming, so if you find any error kindly let me know in the comments below. Now, some basics.</p>

<p>MPI stands for Message Passing Interface which is meant to be a tool to pass messages among various processes to carry out certain task. Processes corresponds to the physical cores available in your system. You can look for the number of cores available in your own computer by going into the task manager (On a windows computer) and looking for it in the Performance tab.</p>

<p><img src="/assets/images/my_system.png" alt="my_system" /></p>

<p>On my system, I have 6 physical cores. This means that I can parallelize my code to a maximum of 6 processes. Now the question is – how to achieve that with python?</p>

<p>Before that we need to understand a bit about MPI and its terminology.</p>

<p><strong>MPI_COMM_WORLD:</strong> MPI uses objects called communicators, which are a collection of processes. The default communicator is called MPI_COMM_WORLD and it encompasses all the processes available. In my case the MPI_COMM_WORLD will look something like this:</p>

<p><img src="/assets/images/comm_world-1.jpeg" alt="comm_world-1" /></p>

<p><strong>World Size:</strong> This would tell the program about the number of processors available in the world.</p>

<p><strong>Processor Rank:</strong> This is a unique number assigned to each processor inside the world. The numbering starts from 0 as shown in the above figure.</p>

<p><strong>Barrier:</strong> As the name suggests this acts as a barrier in the parallel execution. This forces MPI to execute all the commands before the barrier by all the processes. This is required in the situation where you need a certain variable generated by the program in all processes. This will become clear in the example presented below.</p>

<h2 id="how-do-you-run-a-script-in-parallel">How do you run a script in parallel?</h2>

<p>You can run any python script with MPI by typing the following command in terminal:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mpirun -np 6 python3 test-parallel.py
</code></pre></div></div>

<p>This will tell MPI to run test-parallel.py on 6 processors. The thing to understand here is that even though you are running the program on 6 processors, you are not actually doing parallel computations. You are just doing the same computation 6 times. To actually do parallel computations, you need to manually split the code to work parallelly. When you type the above command the system creates 6 different copies of the program file and sends it to 6 different processes.</p>

<p><img src="/assets/images/split.jpeg" alt="split" /></p>

<p>Thus we need to identify the processor number inside the program and execute the commands accordingly. We can identify the processor number by first getting a handle to the world communicator by using command</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="p">.</span><span class="n">COMM_WORLD</span>
</code></pre></div></div>

<p>and then get the size of the world and the rank of the processor by using the commands</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="p">.</span><span class="nc">Get_rank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="p">.</span><span class="nc">Get_size</span><span class="p">()</span>
</code></pre></div></div>

<p>Based on this information we can modify our logic to run on multiple processors. This simple program sums the numbers from a to b and gives us the result. This logic is parallelizable. We can split the whole domain of calculation into the number of processors available and then add the numbers in that domain. Finally, we can add the results of all the processors. The program below is self-explanatory and you can run the same on your machine with the help of <code class="language-plaintext highlighter-rouge">mpirun</code> command.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span>
<span class="kn">from</span> <span class="n">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="p">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="p">.</span><span class="nc">Get_rank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">comm</span><span class="p">.</span><span class="nc">Get_size</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">10000000</span>

<span class="n">num_per_rank</span> <span class="o">=</span> <span class="n">b</span> <span class="o">//</span> <span class="n">size</span> <span class="c1"># the floor division // rounds the result down to the nearest whole number.
</span><span class="n">summ</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">temp</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">rank</span> <span class="o">*</span> <span class="n">num_per_rank</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_per_rank</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">This is processor </span><span class="sh">"</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="sh">"</span><span class="s">and I am summing numbers from</span><span class="sh">"</span><span class="p">,</span> <span class="n">lower_bound</span><span class="p">,</span><span class="sh">"</span><span class="s"> to </span><span class="sh">"</span><span class="p">,</span> <span class="n">upper_bound</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">comm</span><span class="p">.</span><span class="nc">Barrier</span><span class="p">()</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">):</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">temp</span> <span class="o">+</span> <span class="n">i</span>

<span class="n">summ</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">total</span> <span class="o">=</span> <span class="bp">None</span>

<span class="n">comm</span><span class="p">.</span><span class="nc">Barrier</span><span class="p">()</span>
<span class="c1"># collect the partial results and add to the total sum
</span><span class="n">comm</span><span class="p">.</span><span class="nc">Reduce</span><span class="p">(</span><span class="n">summ</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">MPI</span><span class="p">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">stop_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># add the rest numbers to 1 000 000
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_per_rank</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">total</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">total</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">i</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The sum of numbers from 1 to 1 000 000: </span><span class="sh">"</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">time spent with </span><span class="sh">"</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="sh">"</span><span class="s"> threads in milliseconds</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">-----</span><span class="sh">"</span><span class="p">,</span> <span class="nf">int</span><span class="p">((</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">),</span> <span class="sh">"</span><span class="s">-----</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>The only thing to notice is that the input to the loop changes according to the the processor number (rank). Thus instead of looping <code class="language-plaintext highlighter-rouge">b</code> times, each processor has to loop only <code class="language-plaintext highlighter-rouge">num_per_rank</code> times.</p>

<p>Running the above script on a single core result in the following output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜  pre-processing (master) time mpirun -np 1 python3 test-parallel.py
This is processor  0 and I am summing numbers from 1  to  60000000
The sum of numbers from 1 to 1 000 000:  1800000030000000
time spent with  1  threads in milliseconds
----- 5851 -----

real    0m6.824s
user    0m6.800s
sys     0m0.010s
</code></pre></div></div>

<p>and running the same code on 6 cores results in the following output</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>➜  pre-processing (master) time mpirun -np 6 python3 test-parallel.py
This is processor  0 and I am summing numbers from 1  to  10000000
This is processor  2 and I am summing numbers from 20000001  to  30000000
This is processor  3 and I am summing numbers from 30000001  to  40000000
This is processor  4 and I am summing numbers from 40000001  to  50000000
This is processor  1 and I am summing numbers from 10000001  to  20000000
This is processor  5 and I am summing numbers from 50000001  to  60000000
The sum of numbers from 1 to 1 000 000:  1800000030000000
time spent with  6  threads in milliseconds
----- 1668 -----

real    0m1.945s
user    0m11.250s
sys     0m0.200s
</code></pre></div></div>

<p>Thus we have achieved almost a 3.5\(\times\) boost in speed by running the code in parallel. Now, this was a trivial example but in real calculations, we can expect greater speed boosts. I hope you have understood the working of the command mpirun. If you have any doubts feel free to ask them in the comments.</p>

            </div>
            <div class="PageNavigation">
                
                <a class="button button-prev" href="/2019/08/24/gsoc-complete.html" title="GSoC complete: FEniCS-The mesh workflow">&laquo; Previous</a>
                
                
                <a class="button button-next" href="/2020/11/20/new-blog.html" title="Welcome to the new blog">Next &raquo;</a>
                
            </div>
            <!-- ----------------------------------------------------------- -->
            <hr style="/*position: relative; width: 300%;right:calc(200% - 30px);*/ background: var(--color-1);border: none;height: 1px; margin-bottom: 80px; opacity: 1;">
            <div class="flexbox_container_two_col flexbox_container_flip " style="padding-top: 50px;padding-bottom: 50px;">
                <div class="flexbox_item">
                    <div>
                        <p style="font-size:36px; font-family: Montserrat; font-weight: bold; line-height: 1.2; ">Newsletter</p>
                        <p style="font-size:16px; padding-top: 20px; padding-bottom: 30px;">"<em><strong>Quality Research:</strong> A weekly newsletter covering ideas and tools for better academic research.</em>" </p>
                        <a class="ml-onclick-form button button-hello" href="javascript:void(0)" onclick="ml('show', 'uSsXyN', true)">Try the free newsletter</a>
                    </div>
                </div>
                <div class="flexbox_item">
                    <div class="abhi-icon" style="vertical-align: middle;     float: right;"><object data="https://ritesh-avkalan.github.io//assets/svg/newsletter.svg" width="80%" style="pointer-events: none;"> </object></div>
                </div>
            </div>
            <!-- ----------------------------------------------------------- -->
        </div>
    </div>
    <div class="post_item_right hide_mobile">
        <p style="padding-top:200px; font-size: 14px; font-family: Montserrat;">ABOUT THE AUTHOR</p>
        <hr style="/*position: relative; width: 300%;right:calc(200% - 30px);*/ background: var(--color-1);border: none;height: 1px; margin-bottom: 40px;">
        <p style="margin-bottom:20px;font-size: 14px;">Hi, I am <strong>Abhinav Gupta</strong>. I am a researcher at Vanderbilt University, USA. I create content to help you become effective in producing quality research. If you are interested in research, academia, or computational mechanics, make sure to follow me. </p>
        <div style="margin-top:50px;">
            <ul class="social-media-list" style="font-size: 14px;">
                <li>
                    <a class="black-link" href="https://www.linkedin.com/in/abhiguptaio/" target="_blank" rel="noopener noreferrer">[LinkedIn]</a>
                </li>
                <li>
                    <a class="black-link" href="https://github.com/iitrabhi" target="_blank" rel="noopener noreferrer"> [Github]</a>
                </li>
                <li>
                    <a class="black-link" href="https://www.researchgate.net/profile/Abhinav_Gupta52" target="_blank" rel="noopener noreferrer">[RG]</a>
                </li>
                <li>
                    <p>👋</p>
                </li>
            </ul>
        </div>
        <a class="hover_highlight" style="font-size: 14px;" href="https://ritesh-avkalan.github.io//pages/about">Click here to learn more →</a>
        <p style="margin-bottom:50px"></p>
    </div>
</div>
        </div>
    </main>
<div style="min-height: 500px;background-color: #000; width:100%">
    <div class="primary_container">
        <div style="flex: 60%; ">
            <p style="font-family:Montserrat; color:#fff; font-weight:700; margin-top: 50px;">ABHI GUPTA</p>
        </div>
        <div class="hide_mobile" style="flex: 20%;">
            <p style="font-family:Montserrat; color:#888; font-weight:700; margin-top: 50px;">Categories</p>
             <p><a href="https://ritesh-avkalan.github.io//categories/coding"  style="color:#ddd; font-size: 16px;">Coding</a></p>
            <p><a href="https://ritesh-avkalan.github.io//categories/presentation"  style="color:#ddd;font-size: 16px;">Presentation</a></p>
            <p><a href="https://ritesh-avkalan.github.io//categories/productivity"  style="color:#ddd;font-size: 16px;">Productivity</a></p>
        </div>
        <div style="flex: 20%; ">
            <p style="font-family:Montserrat; color:#888; font-weight:700; margin-top: 50px;">Links</p>
           
            <p><a href="https://twitter.com/abhiguptaio"  style="color:#ddd;font-size: 16px;">Twitter</a></p>
            <p><a href="https://www.youtube.com/channel/UCpj8oznjjLwVe5KHOGNrvnQ" style="color:#ddd;font-size: 16px;">YouTube</a></p>

             <p><a href="https://github.com/iitrabhi" style="color:#ddd;font-size: 16px;">GitHub</a></p>
             <p><a href="https://www.linkedin.com/in/abhiguptaio/"  style="color:#ddd;font-size: 16px;">LinkedIn</a></p>

            <p><a href="https://scholar.google.com/citations?user=UfWvIkEAAAAJ"  style="color:#ddd;font-size: 16px;">Google Scholar</a></p>
            <p><a href="https://www.researchgate.net/profile/Abhinav-Gupta-38"  style="color:#ddd;font-size: 16px;">Research Gate</a></p>
            
        </div>
    </div>
</div>
<script src="https://ritesh-avkalan.github.io//assets/js/mode_switcher.js" type="text/javascript"></script>
    <script src="https://ritesh-avkalan.github.io//assets/js/code_block.js" type="text/javascript"></script>
</body>

</html>